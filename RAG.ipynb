{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuvarghese4/Grand-School-Projects--/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2jZBL-4jEkza"
      },
      "outputs": [],
      "source": [
        "# before running the code, run this cell once and restart and run all\n",
        "%%capture --no-stderr\n",
        "%pip install numpy==1.26.4 langchain-community langchain-openai langchain-chroma gradio==3.38\n",
        "%pip install nbimporter\n",
        "%pip install langsmith\n",
        "%pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ehEKBcQ15dcq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c406885f-0ef6-4ef4-827b-304049345c8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-39b990826050>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbimporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_text_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkgutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/components/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotated_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotatedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_plot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBarPlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m from gradio.components.base import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gradio/components/bar_plot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maltair\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocumentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_documentation_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "import ssl\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import nbimporter\n",
        "import gradio as gr\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_chroma.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.agents import Tool, AgentType, initialize_agent\n",
        "from google.colab import drive\n",
        "# ignore the warnings as they do not affect the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjYuUClBpYTN"
      },
      "outputs": [],
      "source": [
        "base_path = '/content' # <- change this to your own base path where you keep the notebook and constant.py\n",
        "os.chdir(base_path)\n",
        "os.listdir(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdJ1FEx8FkwC"
      },
      "outputs": [],
      "source": [
        "# import API KEYS from constant.py\n",
        "from constant import OPENAI_API_KEY, LANGSMITH_API_KEY, HF_TOKEN\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ['LANGSMITH_API_KEY'] = LANGSMITH_API_KEY\n",
        "os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "os.environ['USER_AGENT'] = 'Mozilla/5.0'\n",
        "\n",
        "print(OPENAI_API_KEY[:5])\n",
        "print(LANGSMITH_API_KEY[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ7wDfsn_z9U"
      },
      "outputs": [],
      "source": [
        "# function to get sitemap from the url\n",
        "\n",
        "def get_sitemap(url):\n",
        "    try:\n",
        "        req = Request(\n",
        "            url = url,\n",
        "            headers={'User-Agent': 'Mozilla/5.0'}\n",
        "        )\n",
        "\n",
        "        response = urlopen(req)\n",
        "\n",
        "        encoding = response.headers.get_content_charset('utf-8')\n",
        "\n",
        "        xml_data = response.read().decode(encoding)\n",
        "\n",
        "        xml_soup = BeautifulSoup(xml_data, \"xml\")\n",
        "\n",
        "        return xml_soup\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching sitemap: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u7ZfsVP_7r2"
      },
      "outputs": [],
      "source": [
        "# get xmls related to breast cancer\n",
        "\n",
        "def get_urls(xml):\n",
        "  urls = []\n",
        "  for url in xml.find_all('url'):\n",
        "    if url.find('loc'):\n",
        "      loc = url.find('loc').text\n",
        "      if 'breast' in loc and 'video' not in loc:\n",
        "        urls.append(loc)\n",
        "\n",
        "  return urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u84SOxrPBOFK"
      },
      "outputs": [],
      "source": [
        "# retrieve articles with breast cancer\n",
        "url = \"https://www.cancer.gov/sitemaps/pageinstructions.xml\"\n",
        "xml = get_sitemap(url)\n",
        "urls = get_urls(xml)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls"
      ],
      "metadata": {
        "id": "jRDfebpx7dMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip list"
      ],
      "metadata": {
        "id": "iCvg6UH2_PKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4p0d9NOCTNH"
      },
      "outputs": [],
      "source": [
        "# categorize urls based on file type\n",
        "categorized_urls = {\n",
        "    \"pdf\": [],\n",
        "    \"epub\": [],\n",
        "    \"mobi\": [],\n",
        "    \"html\": [],\n",
        "}\n",
        "\n",
        "for url in urls:\n",
        "    if url.endswith(\".pdf\"):\n",
        "        categorized_urls[\"pdf\"].append(url)\n",
        "    elif url.endswith(\".epub\"):\n",
        "        categorized_urls[\"epub\"].append(url)\n",
        "    elif url.endswith(\".mobi\"):\n",
        "        categorized_urls[\"mobi\"].append(url)\n",
        "    else:\n",
        "        categorized_urls[\"html\"].append(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTLP839ML6O8"
      },
      "outputs": [],
      "source": [
        "# from htmls, exclude pdfs\n",
        "pdf_urls = []\n",
        "\n",
        "for url in categorized_urls['html']:\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "\n",
        "        if \"pdf\" in content_type.lower():\n",
        "            pdf_urls.append(url)\n",
        "            print(f\"Found PDF: {url}\")\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error fetching {url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlygjaunO3l0"
      },
      "outputs": [],
      "source": [
        "categorized_urls[\"html\"] = [url for url in categorized_urls[\"html\"] if url not in pdf_urls]\n",
        "categorized_urls[\"pdf\"].extend(pdf_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifz3ASgkCmG8"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "docs = []\n",
        "for i, url in enumerate(categorized_urls['html']):\n",
        "  loader = WebBaseLoader(url).load()\n",
        "  docs.extend(loader)\n",
        "  if i != 0 and i % 10 == 0:\n",
        "    print(f'{i} html documents are loaded')\n",
        "\n",
        "print('All html documents are loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7OBj3fwWZ_S"
      },
      "outputs": [],
      "source": [
        "# create retriever\n",
        "text_splitters = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitters.split_documents(docs)\n",
        "embedding = OpenAIEmbeddings()\n",
        "vector_db = Chroma.from_documents(documents = documents, embedding = embedding)\n",
        "retriever = vector_db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq_N_2AgYGwm"
      },
      "outputs": [],
      "source": [
        "# create question answer chain\n",
        "system_prompt = (\n",
        "    \"\"\"\n",
        "    You are an assistant in question-answering tasks.\n",
        "    Provide answers using the retrieved context.\n",
        "    If there is no relevent context for the question.\n",
        "    Simply state, No relevant documents.\n",
        "    Be brief and stick to the key points, and try to\n",
        "    use the ordered numeric format if you can.\n",
        "    The number of items does not matter.\n",
        "    Ask follow-up questions if the question is incomplete or not clear\n",
        "    \\n\\n\n",
        "    {context}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', system_prompt),\n",
        "        MessagesPlaceholder('chat_history'),\n",
        "        ('human', '{input}')\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0.0)\n",
        "\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS1cEn-KagPY"
      },
      "outputs": [],
      "source": [
        "# create retriever chain with chat history\n",
        "history_system_prompt = (\n",
        "    \"\"\"\n",
        "    Given chat history and the latest user input, formualte a\n",
        "    standalone question that can be understood without referencing\n",
        "    chat history.\n",
        "\n",
        "    This is NOT telling you to generate answers, but to reformulate\n",
        "    the questions or return them as they are.\n",
        "    \\n\\n\n",
        "    {{context}}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "history_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', history_system_prompt),\n",
        "        MessagesPlaceholder('chat_history'),\n",
        "        ('human', '{input}')\n",
        "    ]\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(llm, retriever, history_prompt)\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVEP3EevbjAk"
      },
      "outputs": [],
      "source": [
        "# test the retirever\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "test_history = []\n",
        "\n",
        "def rag_test():\n",
        "\n",
        "  while True:\n",
        "\n",
        "    question = input('Enter your question: ').strip()\n",
        "\n",
        "    if question.lower() in ['q', 'quit']:\n",
        "      print('Exiting Chat, Goodbye!')\n",
        "      break\n",
        "\n",
        "    response = rag_chain.invoke({'input': question, 'chat_history': test_history})\n",
        "    test_history.extend(\n",
        "        [\n",
        "            HumanMessage(content = question),\n",
        "            AIMessage(content = response.get('answer', 'No response available'))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print('\\nAnswer:\\n')\n",
        "    print(response.get('answer', 'No response available'))\n",
        "    print('-' * 50)\n",
        "    print('\\n')\n",
        "\n",
        "rag_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5Nw7q3e86k"
      },
      "source": [
        "Ask questions like:\n",
        "\n",
        "* What are the risk factors for breast cancer?\n",
        "* How is breast cancer diagnosed?\n",
        "* What are the different stages of breast cancer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB08p_WifCcu"
      },
      "outputs": [],
      "source": [
        "# create function to use rag chain in agent's tool\n",
        "def domain_info(user_input: str, memory:ConversationBufferMemory) -> str:\n",
        "\n",
        "  full_chat_history = memory.load_memory_variables({})['chat_history']\n",
        "\n",
        "  result = rag_chain.invoke(\n",
        "      {'input': user_input, 'chat_history': full_chat_history}\n",
        "  )\n",
        "\n",
        "  answer = result.get('answer', 'No response available')\n",
        "\n",
        "  memory.save_context(\n",
        "      {'input': user_input},\n",
        "      {'output': answer}\n",
        "  )\n",
        "\n",
        "  print(answer)\n",
        "  return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqsDU2QFf295"
      },
      "outputs": [],
      "source": [
        "# create a rag tool for agent\n",
        "domain_rag = Tool(\n",
        "    name = 'DomainRAGInfo',\n",
        "    func = lambda user_input: domain_info(user_input, global_memory),\n",
        "    description = \"\"\"\n",
        "    Use this tool for questions about breast cancer from the knowledge base that may\n",
        "    rely on previous conversation.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "tools = [domain_rag]\n",
        "\n",
        "rag_llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0.0)\n",
        "\n",
        "global_memory = ConversationBufferMemory(\n",
        "    memory_key = 'chat_history',\n",
        "    return_messages = True,\n",
        "    input_key = 'input',\n",
        "    output_key = 'output'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox4s0HWyodSE"
      },
      "outputs": [],
      "source": [
        "# create agent\n",
        "domain_rag_agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = rag_llm,\n",
        "    agent = AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory = global_memory,\n",
        "    verbose = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npGm7SlChLf2"
      },
      "outputs": [],
      "source": [
        "# create agent utilizing function for gradio\n",
        "def domain_rag_agent_fn(user_input, chat_history):\n",
        "    response = domain_rag_agent.run(input=user_input)\n",
        "    chat_history.append((user_input, response))\n",
        "    return chat_history, chat_history, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju3ROf0UzOuQ"
      },
      "outputs": [],
      "source": [
        "# gradio user interface\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "  gr.Markdown('Cancer-QA BOT')\n",
        "\n",
        "  chatbot = gr.Chatbot(type='messages')\n",
        "\n",
        "  user_box = gr.Textbox(\n",
        "      show_label = False,\n",
        "      placeholder = 'Ask any question about cancer'\n",
        "  )\n",
        "\n",
        "  clear_btn = gr.Button('Clear Chat')\n",
        "\n",
        "  user_box.submit(\n",
        "      fn = domain_rag_agent_fn,\n",
        "      inputs = [user_box, chatbot],\n",
        "      outputs = [chatbot, chatbot, user_box]\n",
        "  )\n",
        "\n",
        "  def clear_memory():\n",
        "    global_memory.clear()\n",
        "    return []\n",
        "\n",
        "  clear_btn.click(clear_memory, [], chatbot, queue=False)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}